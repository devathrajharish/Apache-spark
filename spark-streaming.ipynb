{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Streaming\n",
    "### Analyzing data which is coming in real time and analazying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases:\n",
    "- Credit card Fraud detection\n",
    "- Spam filtering\n",
    "- Network intrusion detection\n",
    "- real time social media analytics\n",
    "- stock market analysis\n",
    "\n",
    "## Data Sources spark supports:\n",
    "- Flat Files( as they are created )\n",
    "- TCP/IP\n",
    "- Apache Flume\n",
    "- Apache Kafka\n",
    "- Amazon Kinesis\n",
    "- Social media ( Instagram, Twitter, Facebook )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steaming Context is created from the Spark Context to enable streaming. Then Streaming creates a DStream(Discretized Stream) on which processing occurs\n",
    "- Dstream is broken into micro-batches\n",
    "- Data is received, accumulated as a micro-batch and processed as a micro-batch\n",
    "- Each micro-batch is an RDD\n",
    "- regular transformations and actions can be made on these RDD's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "import os\n",
    "import configparser\n",
    "findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "import pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, we import StreamingContext, which is the main entry point for all streaming functionality.\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "conf = (SparkConf()\n",
    "         .setMaster(\"local[9]\")\n",
    "         .setAppName(\"v2maestros\")\n",
    "         .set(\"spark.executor.memory\", \"1g\"))\n",
    "sc = SparkContext(conf = conf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create a local StreamingContext with two execution threads, and batch interval of 1 second.\n",
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-HIK8PU2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[9]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>v2maestros</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[9] appName=v2maestros>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLines = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = ssc.socketTextStream(\"localhost\", 9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = lines.flatMap(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = words.map(lambda word: (word,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts = pairs.reduceByKey(lambda x, y : x + y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCounts.pprint(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLines = 0\n",
    "linesCount = 0\n",
    "def computeMetrics(rdd):\n",
    "    global totalLines\n",
    "    global linesCount\n",
    "    linesCount = rdd.count()\n",
    "    totalLines += linesCount\n",
    "    print(rdd.collect())\n",
    "    print(\"lines in RDD:\" , linesCount, \" TOtla:\", totalLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines.foreachRDD(computeMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowMetrics(rdd):\n",
    "    print(\"window RDD size:\", rdd.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedRDD = lines.window(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowedRDD.foreachRDD(windowMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:04\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:05\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "window RDD size: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:06\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:07\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "window RDD size: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:08\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:09\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 0\n",
      "window RDD size: 0\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:10\n",
      "-------------------------------------------\n",
      "('wassup?', 1)\n",
      "('hey', 1)\n",
      "\n",
      "['hey wassup?']\n",
      "lines in RDD: 1  TOtla: 1\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:11\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 1\n",
      "window RDD size: 1\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:12\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 1\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:13\n",
      "-------------------------------------------\n",
      "('you', 1)\n",
      "('are', 1)\n",
      "('how', 1)\n",
      "\n",
      "['how are you']\n",
      "lines in RDD: 1  TOtla: 2\n",
      "window RDD size: 2\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:14\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 2\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:15\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 2\n",
      "window RDD size: 1\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:16\n",
      "-------------------------------------------\n",
      "('gud', 1)\n",
      "\n",
      "['gud']\n",
      "lines in RDD: 1  TOtla: 3\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:17\n",
      "-------------------------------------------\n",
      "('bad', 1)\n",
      "\n",
      "['bad']\n",
      "lines in RDD: 1  TOtla: 4\n",
      "window RDD size: 2\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:18\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 4\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:19\n",
      "-------------------------------------------\n",
      "('harish', 1)\n",
      "\n",
      "['harish']\n",
      "lines in RDD: 1  TOtla: 5\n",
      "window RDD size: 3\n",
      "-------------------------------------------\n",
      "Time: 2020-08-12 18:37:20\n",
      "-------------------------------------------\n",
      "\n",
      "[]\n",
      "lines in RDD: 0  TOtla: 5\n"
     ]
    }
   ],
   "source": [
    "ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "- Udemy\n",
    "- https://spark.apache.org/docs/latest/streaming-programming-guide.html\n",
    "- https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
